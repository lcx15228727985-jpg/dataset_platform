import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
import cv2
import numpy as np
import matplotlib.pyplot as plt
import os
import pandas as pd
from mpl_toolkits.mplot3d import Axes3D

# ==========================================
# é…ç½®
# ==========================================
STACK_DATA_ROOT = "/root/asym_pinn_dataset"  # åŸå§‹åˆ‡ç‰‡æ•°æ®
CSV_PATH = os.path.join(STACK_DATA_ROOT, "metadata.csv")
MODEL_PATH = "best_unrolled_model.pth"
DEVICE = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")


# ==========================================
# 1. æ ¸å¿ƒä¿®å¤ï¼šé«˜ç²¾åº¦æŠ•å½±ç®—æ³•
# ==========================================
def precise_stack_projection(stack):
    """
    å°† (Seq_Len, 224, 224) çš„åˆ‡ç‰‡å †å  -> (200, 360) çš„å±•å¼€å›¾
    """
    seq_len, h, w = stack.shape
    center = (w // 2, h // 2)
    max_radius = min(center)

    # 1. æåæ ‡å˜æ¢ (å¯¹æ¯ä¸€å¸§)
    # ç»“æœ: (Seq_Len, 360, Radius)
    polar_stack = []
    for i in range(seq_len):
        # æ—‹è½¬ 90 åº¦ä»¥å¯¹é½ç›¸ä½ (æ ¹æ®ä¹‹å‰æ•°æ®ç”Ÿæˆçš„ç»éªŒ)
        # cv2.warpPolar çš„ 0 åº¦é€šå¸¸åœ¨ 3 ç‚¹é’Ÿæ–¹å‘ï¼Œæˆ‘ä»¬éœ€è¦å¯¹é½ä½ çš„æ•°å­¦ç”Ÿæˆé€»è¾‘
        slice_img = stack[i]

        # æ ¸å¿ƒï¼šæåæ ‡å˜æ¢
        # è¾“å‡ºå°ºå¯¸: (360, max_radius) -> è¡Œæ˜¯è§’åº¦ï¼Œåˆ—æ˜¯åŠå¾„
        polar = cv2.warpPolar(slice_img, (max_radius, 360), center, max_radius, cv2.WARP_POLAR_LINEAR)
        polar_stack.append(polar)

    polar_stack = np.array(polar_stack)  # (5, 360, 112)

    # 2. åŠå¾„è‡ªåŠ¨å¯¹ç„¦ (Auto-Focus)
    # æˆ‘ä»¬ä¸çŸ¥é“ Marker ç¡®åˆ‡åœ¨ç¬¬å‡ ä¸ªåƒç´ åŠå¾„ä¸Šï¼Œä½†é‚£é‡Œè‚¯å®šæœ€äº®
    # åœ¨åŠå¾„ç»´åº¦ä¸Šæ±‚æœ€å¤§å€¼æˆ–è€…æ±‚å’Œ
    # energy_profile: (112,)
    energy_profile = np.mean(polar_stack, axis=(0, 1))

    # æ‰¾åˆ°èƒ½é‡å³°å€¼ (Marker æ‰€åœ¨çš„åŠå¾„ç¯)
    # ä¹Ÿå°±æ˜¯çº¿æŸæœ€äº®çš„é‚£ä¸ªåœˆ
    best_radius_idx = np.argmax(energy_profile)

    # ä¸ºäº†é²æ£’ï¼Œå–å³°å€¼é™„è¿‘çš„ 5 ä¸ªåƒç´ å–æœ€å¤§å€¼ (Max Projection)
    # è¿™æ ·èƒ½æ•æ‰åˆ°ç¨æœ‰åç§»çš„ Marker
    r_start = max(0, best_radius_idx - 3)
    r_end = min(polar_stack.shape[2], best_radius_idx + 3)

    # æå–å±•å¼€å›¾: Shape (Seq_Len, 360)
    # åœ¨åŠå¾„ç»´åº¦åš max pooling
    unrolled_raw = np.max(polar_stack[:, :, r_start:r_end], axis=2)

    # 3. å›¾åƒå¢å¼ºä¸å°ºå¯¸å¯¹é½
    # åŸå§‹ stack åªæœ‰ 5 å¸§ï¼Œè€Œæ¨¡å‹éœ€è¦ 200 è¡Œ
    # å¿…é¡»ä½¿ç”¨ 'nearest' æ’å€¼æˆ–è€… 'linear'ï¼Œä½†è¦å°å¿ƒæ¨¡ç³Š
    # è¿™é‡Œæˆ‘ä»¬ç”¨ Linear æ’å€¼æ¨¡æ‹Ÿè¿ç»­æ€§

    # è½¬ç½®ä¸€ä¸‹å˜æˆ (H=Seq, W=Angle) -> (H=Angle, W=Seq) ä»¥ä¾¿ resize
    # æˆ‘ä»¬çš„ç›®æ ‡æ˜¯ (H=200, W=360)
    # cv2.resize dsize æ˜¯ (width, height)

    # æ³¨æ„ï¼šunrolled_raw æ˜¯ (5, 360) -> 5è¡Œä»£è¡¨æ—¶é—´ï¼Œ360åˆ—ä»£è¡¨è§’åº¦
    unrolled_final = cv2.resize(unrolled_raw, (360, 200), interpolation=cv2.INTER_LINEAR)

    # å½’ä¸€åŒ–åˆ° 0-255
    if unrolled_final.max() > 0:
        unrolled_final = (unrolled_final / unrolled_final.max() * 255).astype(np.uint8)

    # 4. ç›¸ä½å¯¹é½ä¿®æ­£
    # æ­¤æ—¶å¯èƒ½å­˜åœ¨ç›¸ä½åå·® (æ¯”å¦‚æ•´ä½“è½¬äº† 90 åº¦)ï¼Œè¿™å–å†³äº warpPolar çš„å®šä¹‰
    # è¿™æ˜¯ä¸€ä¸ªå·¥ç¨‹ä¸Šçš„ Calibration å‚æ•°ï¼Œé€šå¸¸æ˜¯ä¸€ä¸ªå›ºå®šçš„åƒç´ åç§»
    # è¿™é‡Œå…ˆä¸åšï¼Œç›´æ¥çœ‹æ•ˆæœï¼Œå¦‚æœæ–¹å‘åäº†æˆ–åäº†ï¼Œåªè¦åŠ ä¸ª np.roll å³å¯

    return unrolled_final


# ==========================================
# 2. æ¨¡å‹å®šä¹‰
# ==========================================
class MapResNet(nn.Module):
    def __init__(self):
        super(MapResNet, self).__init__()
        resnet = models.resnet18(pretrained=False)
        self.new_conv = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)
        resnet.conv1 = self.new_conv
        self.backbone = nn.Sequential(*list(resnet.children())[:-1])
        self.fc = nn.Sequential(nn.Linear(512, 256), nn.ReLU(), nn.Linear(256, 3))

    def forward(self, x):
        return self.fc(self.backbone(x).view(x.size(0), -1))


# ==========================================
# 3. å‡ ä½•å·¥å…·
# ==========================================
def pcc_forward(kappa, phi, length=100.0):
    s = np.linspace(0, length, 100)
    if abs(kappa) < 1e-5:
        return np.stack([np.zeros_like(s), np.zeros_like(s), s], axis=1)
    r = 1.0 / kappa;
    theta = s * kappa
    x = r * (1 - np.cos(theta)) * np.cos(phi)
    y = r * (1 - np.cos(theta)) * np.sin(phi)
    z = r * np.sin(theta)
    return np.stack([x, y, z], axis=1)


# ==========================================
# 4. ä¸»ç¨‹åº
# ==========================================
def run_fix_demo():
    if not os.path.exists(MODEL_PATH):
        print("âŒ æ¨¡å‹ä¸å­˜åœ¨")
        return

    model = MapResNet().to(DEVICE)
    model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
    model.eval()

    df = pd.read_csv(CSV_PATH)
    # æ‰¾ä¸€ä¸ªå¼¯æ›²æ¯”è¾ƒæ˜æ˜¾çš„æ ·æœ¬ï¼Œæ–¹ä¾¿è§‚å¯Ÿ
    df_bend = df[df['kappa'] > 0.005]
    if len(df_bend) > 0:
        row = df_bend.sample(1).iloc[0]
    else:
        row = df.sample(1).iloc[0]

    npy_path = os.path.join(STACK_DATA_ROOT, row['filename'])
    stack_3d = np.load(npy_path)

    print(f"ğŸ” æ ·æœ¬: {row['filename']} (True Kappa={row['kappa']:.4f})")

    # === 1. ç”Ÿæˆæ¨ç†ç”¨çš„å›¾ ===
    inference_map = precise_stack_projection(stack_3d)

    # === 2. åŠ è½½ä¸€å¼ è®­ç»ƒé›†é‡Œçš„å›¾(éšä¾¿ä¸€å¼ )åšå¯¹æ¯” ===
    # ä¸ºäº†å¯¹æ¯”ï¼Œæˆ‘ä»¬ç†æƒ³æƒ…å†µä¸‹åº”è¯¥é‡æ–°ç”¨ generate_unrolled ç”Ÿæˆè¿™å¼ å›¾çš„çœŸå€¼
    # ä½†è¿™é‡Œæˆ‘ä»¬ä¸»è¦çœ‹ "ç”»é£" æ˜¯å¦ä¸€è‡´
    # æˆ‘ä»¬ä¸´æ—¶ä» unrolled_dataset é‡Œè¯»ä¸€å¼ æ¥çœ‹çœ‹é£æ ¼
    train_style_img = None
    if os.path.exists("/root/unrolled_dataset/map_00000.png"):
        train_style_img = cv2.imread("/root/unrolled_dataset/map_00000.png", 0)

    # === 3. æ¨ç† ===
    pil_img = Image.fromarray(inference_map).convert('L')
    transform = transforms.Compose([transforms.Resize((200, 360)), transforms.ToTensor()])
    input_tensor = transform(pil_img).unsqueeze(0).to(DEVICE)

    with torch.no_grad():
        pred_norm = model(input_tensor).cpu().numpy()[0]
        pred_tip = pred_norm * 100.0

    # === 4. è¯¯å·®è®¡ç®— ===
    gt_tip = pcc_forward(row['kappa'], row['phi'])[-1]
    error = np.linalg.norm(gt_tip - pred_tip)

    print(f"ğŸ“Š è¯¯å·®: {error:.2f} mm")
    if error > 10:
        print("âš ï¸ è­¦å‘Š: è¯¯å·®ä¾ç„¶è¾ƒå¤§ã€‚è¯·æ£€æŸ¥ä¸‹æ–¹ç”Ÿæˆçš„å¯¹æ¯”å›¾ 'debug_comparison.png'")
        print("   å¦‚æœ 'Inference Input' å’Œ 'Training Style' çœ‹èµ·æ¥æˆªç„¶ä¸åŒ(æ¯”å¦‚é»‘ç™½åäº†ï¼Œæˆ–è€…å…¨æ˜¯å™ªéŸ³)ï¼Œ")
        print("   è¯´æ˜æŠ•å½±å‚æ•°(Radius)è¿˜éœ€è¦å¾®è°ƒã€‚")

    # === 5. ç»˜å›¾è¯Šæ–­ ===
    fig = plt.figure(figsize=(15, 5))

    # è¯Šæ–­ 1: æˆ‘ä»¬ç”Ÿæˆé€ç»™ç½‘ç»œçš„å›¾
    ax1 = fig.add_subplot(1, 3, 1)
    ax1.imshow(inference_map, cmap='gray', aspect='auto')
    ax1.set_title("1. Inference Input (From Stack)")

    # è¯Šæ–­ 2: ç½‘ç»œè®­ç»ƒæ—¶çœ‹è¿‡çš„å›¾ (é£æ ¼å‚è€ƒ)
    ax2 = fig.add_subplot(1, 3, 2)
    if train_style_img is not None:
        ax2.imshow(train_style_img, cmap='gray', aspect='auto')
        ax2.set_title("2. Training Data Style (Ideal)")
    else:
        ax2.text(0.5, 0.5, "No training data found", ha='center')

    # è¯Šæ–­ 3: 3D ç»“æœ
    pts_gt = pcc_forward(row['kappa'], row['phi'])
    # é€†è§£ç”»å›¾
    # ç®€å•ç”¨ç›´çº¿è¿æ¥åŸç‚¹å’Œé¢„æµ‹ç‚¹æ¥ç¤ºæ„è¯¯å·®
    pts_pred_line = np.stack([
        [0, 0, 0],
        pred_tip
    ])

    ax3 = fig.add_subplot(1, 3, 3, projection='3d')
    ax3.plot(pts_gt[:, 0], pts_gt[:, 1], pts_gt[:, 2], 'g-', linewidth=4, label='GT')
    ax3.plot(pts_pred_line[:, 0], pts_pred_line[:, 1], pts_pred_line[:, 2], 'r--', linewidth=2, label='Pred Tip Dir')
    ax3.scatter(gt_tip[0], gt_tip[1], gt_tip[2], c='g', s=100)
    ax3.scatter(pred_tip[0], pred_tip[1], pred_tip[2], c='r', s=100, marker='x')
    ax3.set_xlim([-40, 40]);
    ax3.set_ylim([-40, 40]);
    ax3.set_zlim([0, 100])
    ax3.set_title(f"Error: {error:.1f} mm")
    ax3.legend()

    plt.savefig("debug_comparison.png")
    print("âœ¨ è¯Šæ–­å›¾å·²ä¿å­˜: debug_comparison.png")


if __name__ == "__main__":
    run_fix_demo()