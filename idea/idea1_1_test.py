import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import models, transforms
import pandas as pd
import os
import cv2
import numpy as np
import time
from PIL import Image  # <--- å…³é”®ä¿®å¤ï¼šå¯¼å…¥ PIL

# ==========================================
# é…ç½®åŒºåŸŸ
# ==========================================
# æ•°æ®é›†ç»å¯¹è·¯å¾„
DATA_ROOT = "/root/pinn_dataset"
CSV_PATH = os.path.join(DATA_ROOT, "metadata.csv")
IMG_DIR = os.path.join(DATA_ROOT, "images")

BATCH_SIZE = 64
NUM_EPOCHS = 50
LEARNING_RATE = 1e-4


# ==========================================
# 1. è‡ªå®šä¹‰æ•°æ®é›† (ä¿®å¤ NumPy -> PIL é—®é¢˜)
# ==========================================
class PINNDataset(Dataset):
    def __init__(self, csv_file, img_dir, transform=None):
        self.data = pd.read_csv(csv_file)
        self.img_dir = img_dir
        self.transform = transform

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        # è¯»å–å›¾ç‰‡è·¯å¾„
        img_name = os.path.join(self.img_dir, self.data.iloc[idx]['filename'])

        # OpenCV è¯»å–
        image = cv2.imread(img_name)
        if image is None:
            raise FileNotFoundError(f"æ— æ³•æ‰¾åˆ°å›¾ç‰‡: {img_name}")

        # 1. è½¬ä¸º RGB
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        # 2. å…³é”®ä¿®å¤ï¼šå°† NumPy æ•°ç»„è½¬æ¢ä¸º PIL Image å¯¹è±¡
        # PyTorch çš„ transforms (å¦‚ Resize) æœŸæœ›è¾“å…¥æ˜¯ PIL Image
        image = Image.fromarray(image)

        # è¯»å–ç‰©ç†æ ‡ç­¾
        kappa = self.data.iloc[idx]['kappa']
        phi = self.data.iloc[idx]['phi']
        u_pos = self.data.iloc[idx]['u_position']

        # æ„å»ºæ ‡ç­¾
        labels = torch.tensor([kappa, phi], dtype=torch.float32)
        physics_params = torch.tensor([u_pos], dtype=torch.float32)

        if self.transform:
            image = self.transform(image)

        return image, labels, physics_params


# ==========================================
# 2. PINN æ¨¡å‹ç»“æ„ (ResNet-18 Regressor)
# ==========================================
class RobotPINN(nn.Module):
    def __init__(self):
        super(RobotPINN, self).__init__()
        # åŠ è½½é¢„è®­ç»ƒçš„ ResNet
        self.backbone = models.resnet18(pretrained=True)

        num_ftrs = self.backbone.fc.in_features

        # ä¿®æ”¹å…¨è¿æ¥å±‚ä¸ºå›å½’å¤´
        self.backbone.fc = nn.Sequential(
            nn.Linear(num_ftrs, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, 64),
            nn.ReLU(),
            nn.Linear(64, 2)  # è¾“å‡º [kappa, phi]
        )

    def forward(self, x):
        return self.backbone(x)


# ==========================================
# 3. ç‰©ç†æŸå¤±å‡½æ•° (Physics-Informed Loss)
# ==========================================
class PhysicsLoss(nn.Module):
    def __init__(self, lambda_phy=0.1):
        super(PhysicsLoss, self).__init__()
        self.mse = nn.MSELoss()
        self.lambda_phy = lambda_phy

    def forward(self, preds, targets, u_pos):
        # --- A. æ•°æ®é©±åŠ¨æŸå¤± (Data Loss) ---
        pred_kappa = preds[:, 0]
        true_kappa = targets[:, 0]

        pred_phi = preds[:, 1]
        true_phi = targets[:, 1]

        # ç»™ kappa æ›´é«˜çš„æƒé‡ (x1000)ï¼Œå› ä¸ºå®ƒçš„æ•°å€¼å¾ˆå° (0.001 ~ 0.02)
        # è€Œ phi æ•°å€¼å¾ˆå¤§ (0 ~ 6.28)ï¼Œä¸åŠ æƒé‡ä¼šå¯¼è‡´æ¨¡å‹åªå­¦ phi å¿½ç•¥ kappa
        loss_kappa = self.mse(pred_kappa, true_kappa) * 1000.0
        loss_phi = self.mse(pred_phi, true_phi)

        loss_data = loss_kappa + loss_phi

        # --- B. ç‰©ç†çº¦æŸæŸå¤± (Physics Constraint) ---
        # çº¦æŸ: æ›²ç‡ kappa åº”è¯¥ >= 0
        loss_negative_kappa = torch.mean(torch.relu(-pred_kappa))

        # æ€»æŸå¤±
        total_loss = loss_data + self.lambda_phy * loss_negative_kappa

        return total_loss, loss_kappa.item(), loss_phi.item()


# ==========================================
# 4. è®­ç»ƒä¸»ç¨‹åº
# ==========================================
def train_pinn():
    # æ£€æŸ¥æ•°æ®
    if not os.path.exists(CSV_PATH):
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°å…ƒæ•°æ®æ–‡ä»¶ {CSV_PATH}")
        print("è¯·å…ˆè¿è¡Œæ•°æ®ç”Ÿæˆè„šæœ¬ï¼")
        return

    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ”¥ Training on: {device}")

    # æ•°æ®é¢„å¤„ç†
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
    ])

    # åŠ è½½æ•°æ®é›†
    full_dataset = PINNDataset(CSV_PATH, IMG_DIR, transform=transform)

    # åˆ’åˆ†è®­ç»ƒ/éªŒè¯é›†
    train_size = int(0.8 * len(full_dataset))
    val_size = len(full_dataset) - train_size
    train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])

    # Windows/Linux å…¼å®¹æ€§ï¼šå¦‚æœæŠ¥é”™ï¼Œå°è¯•æŠŠ num_workers æ”¹ä¸º 0
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)

    print(f"è®­ç»ƒé›†: {len(train_dataset)} | éªŒè¯é›†: {len(val_dataset)}")

    # åˆå§‹åŒ–æ¨¡å‹
    model = RobotPINN().to(device)

    # ä¼˜åŒ–å™¨
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

    # æŸå¤±å‡½æ•°
    criterion = PhysicsLoss(lambda_phy=1.0)

    # å­¦ä¹ ç‡è°ƒæ•´
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, verbose=True)

    # è®­ç»ƒå¾ªç¯
    best_loss = float('inf')

    print("ğŸš€ å¼€å§‹ PINN å›å½’è®­ç»ƒ...")

    for epoch in range(NUM_EPOCHS):
        print(f'\nEpoch {epoch + 1}/{NUM_EPOCHS}')
        print('-' * 30)

        for phase in ['train', 'val']:
            if phase == 'train':
                model.train()
                dataloader = train_loader
            else:
                model.eval()
                dataloader = val_loader

            running_loss = 0.0
            running_kappa_loss = 0.0

            for imgs, targets, u_pos in dataloader:
                imgs = imgs.to(device)
                targets = targets.to(device)
                u_pos = u_pos.to(device)

                optimizer.zero_grad()

                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(imgs)
                    loss, l_k, l_p = criterion(outputs, targets, u_pos)

                    if phase == 'train':
                        loss.backward()
                        optimizer.step()

                running_loss += loss.item() * imgs.size(0)
                running_kappa_loss += l_k * imgs.size(0)

            epoch_loss = running_loss / len(dataloader.dataset)
            epoch_kappa_loss = running_kappa_loss / len(dataloader.dataset)

            # æ‰“å°æ ¼å¼åŒ–ï¼šæ€»Loss å’Œ æ›²ç‡è¯¯å·®
            print(f'{phase:<5} Total Loss: {epoch_loss:.4f} | Kappa MSE (x1000): {epoch_kappa_loss:.4f}')

            if phase == 'val':
                scheduler.step(epoch_loss)
                if epoch_loss < best_loss:
                    best_loss = epoch_loss
                    torch.save(model.state_dict(), 'best_pinn_regressor.pth')
                    print("  --> ğŸŒŸ æ¨¡å‹å·²ä¿å­˜ (New Best)")

    print(f"\nâœ… è®­ç»ƒå®Œæˆ! Min Val Loss: {best_loss:.4f}")


if __name__ == "__main__":
    train_pinn()