import torch
import numpy as np
import os
from tqdm import tqdm
import math

# --- å¼•å…¥æ ¸å¿ƒæ¨¡å— ---
from modules.texture import HelicalChirpTexture
from modules.geometry import GeometryEngine
# å°è¯•å…¼å®¹å¯¼å…¥
try:
    from modules.ultrasound import UltrasoundScanner
except ImportError:
    from modules.ultrasound import FastUltrasoundScanner as UltrasoundScanner

def generate_dataset(
    output_path, 
    n_samples=20000, 
    batch_size=128, 
    robot_diameter=21.0, 
    probe_width=25.0
):
    print(f"ğŸš€ å¼€å§‹ç”Ÿæˆæ•°æ®é›†: {output_path}")
    print(f"   æ ·æœ¬æ•°: {n_samples} | Batch: {batch_size}")
    print(f"   ç‰©ç†å‚æ•°: Robot Dia={robot_diameter}mm, Probe Width={probe_width}mm")
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"   ä½¿ç”¨è®¾å¤‡: {device}")

    # 1. åˆå§‹åŒ–ä»¿çœŸç³»ç»Ÿ
    # ---------------------------------------------------------
    tex = HelicalChirpTexture(max_height=3.0).to(device)
    # å°è¯•åŠ è½½ä¼˜åŒ–åçš„çº¹ç†ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨é»˜è®¤/éšæœº
    if os.path.exists("optimized_texture.pth"):
        tex.load_state_dict(torch.load("optimized_texture.pth", map_location=device))
        print("   âœ… å·²åŠ è½½ä¼˜åŒ–çº¹ç†: optimized_texture.pth")
    else:
        print("   âš ï¸ æœªæ‰¾åˆ°ä¼˜åŒ–çº¹ç†ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–")

    geo = GeometryEngine().to(device)
    
    # åˆå§‹åŒ–æ‰«æä»ª (è®¾ç½®ç‰©ç†å‚æ•°)
    scan = UltrasoundScanner(
        probe_width=probe_width, 
        image_depth=8.0, 
        radius=robot_diameter / 2.0
    ).to(device)

    # 2. å‡†å¤‡æ•°æ®å®¹å™¨
    # ---------------------------------------------------------
    data_images = []
    data_labels = []
    
    # è®¡ç®—éœ€è¦å¤šå°‘ä¸ª Batch
    n_batches = int(np.ceil(n_samples / batch_size))
    
    # 3. å¾ªç¯ç”Ÿæˆ
    # ---------------------------------------------------------
    with torch.no_grad():
        for i in tqdm(range(n_batches), desc="Generating Batches"):
            # åŠ¨æ€è°ƒæ•´æœ€åä¸€ä¸ª batch çš„å¤§å°
            current_batch_size = min(batch_size, n_samples - i * batch_size)
            if current_batch_size <= 0: break
            
            # --- A. éšæœºçŠ¶æ€é‡‡æ · (Random Sampling) ---
            
            # 1. Zè½´ä½ç½® [10, 90] mm
            z_pos = torch.rand(current_batch_size, device=device) * 80.0 + 10.0
            
            # 2. ç¯å‘è§’åº¦ Theta [0, 2pi]
            theta = torch.rand(current_batch_size, device=device) * 2 * np.pi
            
            # 3. åˆ‡é¢æ—‹è½¬ Yaw (Scan Angle) [-30, 30] åº¦
            # è½¬æ¢ä¸ºå¼§åº¦: +/- 30 deg ~= +/- 0.52 rad
            yaw_range = np.deg2rad(30.0)
            yaw = (torch.rand(current_batch_size, device=device) * 2 - 1) * yaw_range
            
            # 4. ä¿¯ä»°å€¾æ–œ Pitch (Tilt Angle) [-20, 20] åº¦
            # è½¬æ¢ä¸ºå¼§åº¦: +/- 20 deg ~= +/- 0.35 rad
            pitch_range = np.deg2rad(20.0)
            pitch = (torch.rand(current_batch_size, device=device) * 2 - 1) * pitch_range
            
            # 5. æ›²ç‡ Kappa (æ··åˆé‡‡æ ·ç­–ç•¥)
            # 50% æ˜æ˜¾å¼¯æ›² [0.005, 0.025]
            # 30% è½»å¾®å¼¯æ›² [0.0, 0.005]
            # 20% å®Œå…¨ç›´çº¿ [0.0]
            rand_k = torch.rand(current_batch_size, device=device)
            kappa = torch.zeros(current_batch_size, device=device)
            
            mask_large = rand_k < 0.5
            mask_small = (rand_k >= 0.5) & (rand_k < 0.8)
            # mask_zero = rand_k >= 0.8 (é»˜è®¤ä¸º0)
            
            kappa[mask_large] = torch.rand(mask_large.sum(), device=device) * 0.02 + 0.005
            kappa[mask_small] = torch.rand(mask_small.sum(), device=device) * 0.005
            
            # 6. å¼¯æ›²æ–¹å‘ Phi [0, 2pi]
            phi = torch.rand(current_batch_size, device=device) * 2 * np.pi
            
            # --- B. ä»¿çœŸæˆåƒ (Simulation Pipeline) ---
            
            # 1. å‡†å¤‡çº¹ç†å…¨å›¾
            full_tex, _ = tex()
            # æ‰©å±• Batch: [1, 1, H, W] -> [B, 1, H, W]
            tex_in = full_tex
            if tex_in.dim() == 2: tex_in = tex_in.unsqueeze(0).unsqueeze(0)
            elif tex_in.dim() == 3: tex_in = tex_in.unsqueeze(0)
            tex_in = tex_in.expand(current_batch_size, -1, -1, -1)
            
            # 2. è·å–å…‰çº¿è¿½è¸ªç½‘æ ¼ (Ray Casting Grid)
            # è¾“å…¥éœ€è¦ reshape ä¸º [B, 1]
            z_in = z_pos.unsqueeze(1)
            th_in = theta.unsqueeze(1)
            yaw_in = yaw.unsqueeze(1)
            pitch_in = pitch.unsqueeze(1)
            
            # grid_z, grid_th shape: [B, H_img, W_img]
            grid_z, grid_th = scan.get_slice_grid(z_in, th_in, scan_angle=yaw_in, tilt_angle=pitch_in)
            
            # 3. å‡ ä½•é‡‡æ ·
            # éœ€è¦å±•å¹³ä¸º [B, N] å–‚ç»™ GeometryEngine
            B, H, W = grid_z.shape
            grid_z_flat = grid_z.reshape(B, -1)
            grid_th_flat = grid_th.reshape(B, -1)
            
            # å‡ ä½•è®¡ç®—
            # kappa, phi ä¹Ÿéœ€è¦ [B, 1]
            kap_in = kappa.unsqueeze(1)
            phi_in = phi.unsqueeze(1)
            
            h_map_flat = geo(tex_in, kap_in, phi_in, grid_z_flat, grid_th_flat)
            h_map = h_map_flat.view(B, H, W)
            
            # 4. æ¸²æŸ“å›¾åƒ
            us_img = scan.render_slice(h_map) # [B, 1, H, W]
            
            # 5. æ·»åŠ éšæœºå™ªå£° (Data Augmentation)
            # éšæœºå™ªå£°æ°´å¹³ 0.2 ~ 0.6
            noise_levels = torch.rand(current_batch_size, 1, 1, 1, device=device) * 0.4 + 0.2
            noise = torch.randn_like(us_img)
            us_img_noisy = us_img + us_img * noise * noise_levels
            us_img_final = torch.clamp(us_img_noisy, 0, 1)
            
            # --- C. æ ‡ç­¾ç¼–ç  (Label Encoding) ---
            # æˆ‘ä»¬å°†æ„å»ºä¸€ä¸ª 8ç»´ æ ‡ç­¾å‘é‡
            # Y = [Norm_Z, sin_th, cos_th, sin_yaw, sin_pitch, Norm_Kappa, sin_phi, cos_phi]
            
            # 1. å½’ä¸€åŒ– Z: [10, 90] -> [-1, 1]
            norm_z = (z_pos - 50.0) / 40.0 
            
            # 2. è§’åº¦ç¼–ç 
            sin_th = torch.sin(theta)
            cos_th = torch.cos(theta)
            
            # Yaw å’Œ Pitch èŒƒå›´è¾ƒå°ï¼Œsin å€¼è¿‘ä¼¼çº¿æ€§ï¼Œä½†ä¹Ÿå¯ç”¨
            sin_yaw = torch.sin(yaw)
            sin_pitch = torch.sin(pitch)
            
            # 3. å½’ä¸€åŒ– Kappa: [0, 0.025] -> [0, 1]
            norm_kappa = kappa / 0.025
            
            # 4. å¼¯æ›²æ–¹å‘
            sin_phi = torch.sin(phi)
            cos_phi = torch.cos(phi)
            
            # å †å æ ‡ç­¾
            # Shape: [B, 8]
            labels = torch.stack([
                norm_z,      # 0
                sin_th,      # 1
                cos_th,      # 2
                sin_yaw,     # 3
                sin_pitch,   # 4
                norm_kappa,  # 5
                sin_phi,     # 6
                cos_phi      # 7
            ], dim=1)
            
            # æ”¶é›†æ•°æ® (è½¬å› CPU èŠ‚çœæ˜¾å­˜)
            data_images.append(us_img_final.cpu().to(torch.float32)) # ä¹Ÿå¯ä»¥å­˜ uint8 èŠ‚çœç©ºé—´
            data_labels.append(labels.cpu().to(torch.float32))

    # 4. åˆå¹¶ä¸ä¿å­˜
    # ---------------------------------------------------------
    print("ğŸ“¦ æ­£åœ¨æ‰“åŒ…æ•°æ®...")
    all_images = torch.cat(data_images, dim=0)
    all_labels = torch.cat(data_labels, dim=0)
    
    # æˆªæ–­å¤šä½™çš„æ ·æœ¬ (ç”±äº batch å‘ä¸Šå–æ•´)
    all_images = all_images[:n_samples]
    all_labels = all_labels[:n_samples]
    
    print(f"   Images Shape: {all_images.shape}")
    print(f"   Labels Shape: {all_labels.shape}")
    print("   Label Definition: [Norm_Z, sin_th, cos_th, sin_yaw, sin_pitch, Norm_K, sin_phi, cos_phi]")
    
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    torch.save({'images': all_images, 'labels': all_labels}, output_path)
    print(f"âœ… æ•°æ®é›†å·²ä¿å­˜è‡³: {output_path}")

if __name__ == "__main__":
    # 1. ç”Ÿæˆè®­ç»ƒé›† (20,000 å¼ )
    generate_dataset(
        "dataset/train_data_6dof.pt", 
        n_samples=20000, 
        batch_size=64 # å¦‚æœæ˜¾å­˜ä¸å¤Ÿï¼Œè°ƒå°è¿™é‡Œ
    )
    
    # 2. ç”ŸæˆéªŒè¯é›† (2,000 å¼ )
    generate_dataset(
        "dataset/val_data_6dof.pt", 
        n_samples=2000, 
        batch_size=64
    )