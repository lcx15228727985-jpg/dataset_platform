import torch
import numpy as np
import os
from tqdm import tqdm
import math

# --- å¼•å…¥æ ¸å¿ƒæ¨¡å— ---
from modules.texture import HelicalChirpTexture
from modules.geometry import GeometryEngine
try:
    from modules.ultrasound import UltrasoundScanner
except ImportError:
    from modules.ultrasound import FastUltrasoundScanner as UltrasoundScanner
import torch.nn.functional as F

def generate_simple_dataset(
    output_path, 
    n_samples=10000, 
    batch_size=64, 
    robot_diameter=21.0, 
    probe_width=25.0
):
    print(f"ğŸ§ª å¼€å§‹ç”Ÿæˆ[ç®€åŒ–ç‰ˆ]æ•°æ®é›† (3-DoF): {output_path}")
    print(f"   é”å®š: Yaw=0, Pitch=0")
    print(f"   å˜é‡: Z-axis, Theta, Curvature")
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # 1. åˆå§‹åŒ–ç³»ç»Ÿ
    tex = HelicalChirpTexture(max_height=3.0).to(device)
    geo = GeometryEngine().to(device)
    scan = UltrasoundScanner(probe_width=probe_width, image_depth=8.0, radius=robot_diameter/2.0).to(device)
    
    data_images = []
    data_labels = []
    
    n_batches = int(np.ceil(n_samples / batch_size))
    
    with torch.no_grad():
        for i in tqdm(range(n_batches), desc="Generating 3-DoF Data"):
            current_batch_size = min(batch_size, n_samples - i * batch_size)
            if current_batch_size <= 0: break
            
            # --- A. ç®€åŒ–é‡‡æ · (Simplified Sampling) ---
            
            # 1. Zè½´ä½ç½®: éšæœº
            z_pos = torch.rand(current_batch_size, device=device) * 80.0 + 10.0
            
            # 2. ç¯å‘è§’åº¦ Theta: éšæœº
            theta = torch.rand(current_batch_size, device=device) * 2 * np.pi
            
            # 3. [å›ºå®š] åˆ‡é¢æ—‹è½¬ Yaw = 0
            yaw = torch.zeros(current_batch_size, device=device)
            
            # 4. [å›ºå®š] ä¿¯ä»°å€¾æ–œ Pitch = 0 (æ— è§†å·®)
            pitch = torch.zeros(current_batch_size, device=device)
            
            # 5. æ›²ç‡ Kappa: éšæœº
            rand_k = torch.rand(current_batch_size, device=device)
            kappa = torch.zeros(current_batch_size, device=device)
            mask_curve = rand_k < 0.7 # 70% å¼¯æ›²ï¼Œ30% ç›´çº¿
            kappa[mask_curve] = torch.rand(mask_curve.sum(), device=device) * 0.025
            
            # 6. å¼¯æ›²æ–¹å‘ Phi: éšæœº
            phi = torch.rand(current_batch_size, device=device) * 2 * np.pi
            
            # --- B. ä»¿çœŸæˆåƒ ---
            full_tex, _ = tex()
            
            # [ğŸ”¥ ç»´åº¦ä¿®å¤æ ¸å¿ƒä»£ç ] 
            # æ— è®ºè¾“å…¥æ˜¯ [H, W], [1, H, W] è¿˜æ˜¯ [1, 1, H, W]ï¼Œéƒ½ç»Ÿä¸€å¤„ç†
            tex_in = full_tex
            if tex_in.dim() == 2:   # [H, W]
                tex_in = tex_in.unsqueeze(0).unsqueeze(0)
            elif tex_in.dim() == 3: # [C, H, W]
                tex_in = tex_in.unsqueeze(0)
            # å¦‚æœå·²ç»æ˜¯ 4ç»´ [B, C, H, W]ï¼Œå°±ä¸ç”¨åŠ¨äº†
            
            # å®‰å…¨æ‰©å±•åˆ° Batch Size
            # ç›®æ ‡å½¢çŠ¶: [current_batch_size, 1, H, W]
            tex_in = tex_in.expand(current_batch_size, -1, -1, -1)
            
            # è·å–ç½‘æ ¼ (Pitch=0, Yaw=0)
            grid_z, grid_th = scan.get_slice_grid(
                z_pos.unsqueeze(1), theta.unsqueeze(1), 
                scan_angle=yaw.unsqueeze(1), tilt_angle=pitch.unsqueeze(1)
            )
            
            B, H, W = grid_z.shape
            grid_z_flat = grid_z.reshape(B, -1)
            grid_th_flat = grid_th.reshape(B, -1)
            
            h_map = geo(
                tex_in, 
                kappa.unsqueeze(1), 
                phi.unsqueeze(1), 
                grid_z_flat, 
                grid_th_flat
            ).view(B, H, W)
            
            us_img = scan.render_slice(h_map)
            
            # æ·»åŠ å™ªå£°
            noise = torch.randn_like(us_img)
            us_img = us_img + us_img * noise * 0.5 # é€‚ä¸­å™ªå£°
            us_img = torch.clamp(us_img, 0, 1)
            
            # --- C. æ ‡ç­¾ ---
            norm_z = (z_pos - 50.0) / 40.0 
            norm_kappa = kappa / 0.025
            
            labels = torch.stack([
                norm_z,                  # 0: Z
                torch.sin(theta),        # 1: sin_th
                torch.cos(theta),        # 2: cos_th
                torch.zeros_like(yaw),   # 3: sin_yaw (Always 0)
                torch.zeros_like(pitch), # 4: sin_pitch (Always 0)
                norm_kappa,              # 5: Kappa
                torch.sin(phi),          # 6: sin_phi
                torch.cos(phi)           # 7: cos_phi
            ], dim=1)
            
            data_images.append(us_img.cpu().to(torch.float32))
            data_labels.append(labels.cpu().to(torch.float32))

    print("ğŸ“¦ æ‰“åŒ…æ•°æ®...")
    all_images = torch.cat(data_images, dim=0)
    all_labels = torch.cat(data_labels, dim=0)
    
    save_dict = {'images': all_images, 'labels': all_labels}
    
    # ä¿å­˜è®­ç»ƒé›†
    torch.save(save_dict, output_path)
    print(f"âœ… [ç®€åŒ–ç‰ˆ] è®­ç»ƒé›†å·²ä¿å­˜: {output_path}")
    
    # é¡ºä¾¿ç”Ÿæˆä¸€ä¸ªå°éªŒè¯é›†
    val_path = output_path.replace("train", "val")
    n_val = int(n_samples * 0.1)
    val_dict = {
        'images': all_images[-n_val:],
        'labels': all_labels[-n_val:]
    }
    train_dict = {
        'images': all_images[:-n_val],
        'labels': all_labels[:-n_val:] # æ³¨æ„è¿™é‡Œä¹‹å‰çš„ä»£ç æœ‰ä¸ªå° typoï¼Œè¿™é‡Œä¿®æ­£äº†åˆ‡ç‰‡
    }
    # è¦†ç›–ä¿å­˜è®­ç»ƒé›†ï¼ˆå»é™¤éªŒè¯éƒ¨åˆ†ï¼‰
    torch.save(train_dict, output_path)
    # ä¿å­˜éªŒè¯é›†
    torch.save(val_dict, val_path)
    print(f"âœ… [ç®€åŒ–ç‰ˆ] éªŒè¯é›†å·²ä¿å­˜: {val_path}")

if __name__ == "__main__":
    generate_simple_dataset("dataset/train_data_3dof.pt", n_samples=10000)