import torch
import numpy as np
import matplotlib.pyplot as plt
import os
from tqdm import tqdm

# å¼•å…¥æ¨¡å—
from modules.texture import HelicalChirpTexture
from modules.geometry import GeometryEngine
try:
    from modules.ultrasound import UltrasoundScanner
except ImportError:
    from modules.ultrasound import FastUltrasoundScanner as UltrasoundScanner

# å°è¯•å¼•å…¥ skimage
try:
    from skimage.metrics import structural_similarity as ssim
    HAS_SKIMAGE = True
except ImportError:
    HAS_SKIMAGE = False
    print("âš ï¸ æœªæ£€æµ‹åˆ° scikit-imageï¼ŒSSIM å°†å›é€€ä¸º NCC è®¡ç®—ã€‚å»ºè®® pip install scikit-image")

# --- ç§»æ¤è‡ª train_texture.py çš„å®‰å…¨æ¸²æŸ“å‡½æ•° ---
def render_b_mode_safe(scanner, height_profile):
    """
    Args:
        height_profile: [B, W] è¡¨é¢é«˜åº¦æ›²çº¿
    Returns:
        intensity: [B, H_img, W]
    """
    B, W = height_profile.shape
    H_img = scanner.H_img
    device = height_profile.device
    
    depth_grid = torch.linspace(0, scanner.image_depth, H_img, device=device).view(1, -1, 1)
    surface_depth = scanner.probe_offset - height_profile.unsqueeze(1)
    diff = depth_grid - surface_depth
    
    thickness = scanner.res_axial * 1.5
    intensity = torch.exp(-(diff**2) / (2 * thickness**2))
    
    dz = torch.abs(height_profile[:, 1:] - height_profile[:, :-1])
    dz = torch.cat([dz, dz[:, -1:]], dim=1)
    reflectivity = 1.0 / (1.0 + 8.0 * (dz ** 2))
    
    return intensity * reflectivity.unsqueeze(1)

def calculate_ncc(img1, img2):
    v1 = img1.flatten()
    v2 = img2.flatten()
    v1 = v1 - np.mean(v1)
    v2 = v2 - np.mean(v2)
    norm1 = np.linalg.norm(v1)
    norm2 = np.linalg.norm(v2)
    if norm1 == 0 or norm2 == 0: return 0.0
    return np.dot(v1, v2) / (norm1 * norm2)

def calculate_ssim_simple(img1, img2):
    if HAS_SKIMAGE:
        return ssim(img1, img2, data_range=img2.max() - img2.min())
    else:
        return calculate_ncc(img1, img2)

def check_global_uniqueness():
    print("ğŸŒ å¯åŠ¨å…¨å±€å”¯ä¸€æ€§éªŒè¯ (Global Uniqueness Check)...")
    
    device = torch.device("cpu") # æµ‹è¯•é€šå¸¸ç”¨ CPU å³å¯
    
    # 1. åŠ è½½ç³»ç»Ÿ
    tex = HelicalChirpTexture(max_height=3.0).to(device)
    weights = ["optimized_texture.pth", "initial_texture.pth"]
    for w in weights:
        if os.path.exists(w):
            tex.load_state_dict(torch.load(w, map_location=device))
            print(f"âœ… å·²åŠ è½½çº¹ç†æƒé‡: {w}")
            break
            
    geo = GeometryEngine().to(device)
    # æ³¨æ„è¿™é‡ŒåŠå¾„æœ€å¥½ä¸è®­ç»ƒä¸€è‡´
    scan = UltrasoundScanner(probe_width=30.0, image_depth=8.0, radius=10.5).to(device)
    
    # 2. å…¨å±€éšæœºé‡‡æ ·
    N_SAMPLES = 100 
    print(f"ğŸ² åœ¨å…¨å±€ç©ºé—´éšæœºé‡‡æ · {N_SAMPLES} ä¸ªçŠ¶æ€ç‚¹...")
    
    # éšæœºç”Ÿæˆå‚æ•°å¹¶æŒ‰ Z æ’åº
    z_vals = np.random.uniform(15.0, 85.0, N_SAMPLES)
    theta_vals = np.random.uniform(0, 360, N_SAMPLES)
    kappa_vals = np.random.uniform(0, 0.025, N_SAMPLES)
    phi_vals = np.random.uniform(0, 360, N_SAMPLES)
    
    sort_idx = np.argsort(z_vals)
    z_vals = z_vals[sort_idx]
    theta_vals = theta_vals[sort_idx]
    kappa_vals = kappa_vals[sort_idx]
    phi_vals = phi_vals[sort_idx]
    
    images = []
    print("ğŸ“¸ ç”Ÿæˆæ¨¡æ‹Ÿå›¾åƒä¸­...")
    
    with torch.no_grad():
        full_tex, _ = tex()
        full_tex_batch = full_tex.expand(1, -1, -1, -1) # [1, 1, H, W]
        
        for i in tqdm(range(N_SAMPLES)):
            # å‡†å¤‡å‚æ•° [1]
            z_t = torch.tensor([z_vals[i]], dtype=torch.float32)
            th_t = torch.tensor([np.deg2rad(theta_vals[i])], dtype=torch.float32)
            k_t = torch.tensor([kappa_vals[i]], dtype=torch.float32).unsqueeze(1)
            p_t = torch.tensor([np.deg2rad(phi_vals[i])], dtype=torch.float32).unsqueeze(1)
            
            # [ä¿®å¤ 1] ä½¿ç”¨ get_slice_grid è€Œä¸æ˜¯ get_scan_line_grid
            grid_z, grid_th = scan.get_slice_grid(z_t, th_t)
            
            # [ä¿®å¤ 2] å±•å¹³ç½‘æ ¼åå†ä¼ ç»™ geo
            h_flat = geo(
                full_tex_batch, k_t, p_t, 
                grid_z.reshape(1, -1), 
                grid_th.reshape(1, -1)
            )
            
            # [ä¿®å¤ 3] æ¢å¤å½¢çŠ¶å¹¶å–è¡¨é¢ [1, H_img, W_img] -> å– dim 1 çš„ç¬¬ 0 ä¸ª (è¡¨é¢)
            h_surface = h_flat.reshape(1, scan.H_img, scan.W_img)[:, 0, :] # [1, W]
            
            # [ä¿®å¤ 4] ä½¿ç”¨å®‰å…¨æ¸²æŸ“å™¨
            img = render_b_mode_safe(scan, h_surface)
            
            images.append(img.squeeze().numpy())

    # 3. è®¡ç®—ç›¸å…³æ€§
    print("ğŸ§® è®¡ç®— N x N ç›¸å…³æ€§çŸ©é˜µ...")
    ncc_matrix = np.zeros((N_SAMPLES, N_SAMPLES))
    ssim_matrix = np.zeros((N_SAMPLES, N_SAMPLES))
    
    for i in range(N_SAMPLES):
        for j in range(N_SAMPLES):
            if i == j:
                ncc_matrix[i, j] = 1.0
                ssim_matrix[i, j] = 1.0
            else:
                ncc_matrix[i, j] = calculate_ncc(images[i], images[j])
                ssim_matrix[i, j] = calculate_ssim_simple(images[i], images[j])

    # 4. ç»Ÿè®¡ä¸ç»˜å›¾
    mask = ~np.eye(N_SAMPLES, dtype=bool)
    avg_ncc = ncc_matrix[mask].mean()
    max_ncc = ncc_matrix[mask].max()
    
    print("\nğŸ“Š å…¨å±€ç»Ÿè®¡æŠ¥å‘Š:")
    print(f"   > å¹³å‡äº’ç›¸å…³ (Avg NCC): {avg_ncc:.4f}")
    print(f"   > æœ€å¤§äº’ç›¸å…³ (Max NCC): {max_ncc:.4f}")
    
    fig, axes = plt.subplots(1, 2, figsize=(16, 7))
    
    im1 = axes[0].imshow(ncc_matrix, cmap='inferno', vmin=0.0, vmax=1.0)
    axes[0].set_title(f"NCC Matrix (Sorted by Z)\nGlobal Uniqueness (N={N_SAMPLES})")
    axes[0].set_xlabel("Sample Index (Z sorted)")
    axes[0].set_ylabel("Sample Index")
    plt.colorbar(im1, ax=axes[0])
    
    im2 = axes[1].imshow(ssim_matrix, cmap='inferno', vmin=0.0, vmax=1.0)
    axes[1].set_title(f"SSIM Matrix (Sorted by Z)")
    axes[1].set_xlabel("Sample Index (Z sorted)")
    plt.colorbar(im2, ax=axes[1])
    
    plt.tight_layout()
    plt.savefig("global_uniqueness.png")
    print("âœ… ç»“æœå·²ä¿å­˜è‡³ global_uniqueness.png")

if __name__ == "__main__":
    check_global_uniqueness()