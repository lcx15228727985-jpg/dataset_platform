import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision import models
import pandas as pd
import numpy as np
import cv2
from tqdm import tqdm
import matplotlib.pyplot as plt

# ================= é…ç½®åŒºåŸŸ =================
DATASET_DIR = "dataset_engraving_v1"  # æ•°æ®é›†è·¯å¾„
BATCH_SIZE = 32
LEARNING_RATE = 1e-4
NUM_EPOCHS = 30  # ç¨å¾®å¢åŠ è½®æ•°ï¼Œè®©è‡ªåŠ¨æƒé‡æœ‰æ—¶é—´æ”¶æ•›
TEST_SPLIT = 0.2
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ================= 1. æ•°æ®é›†å®šä¹‰ (å¸¦å½’ä¸€åŒ–) =================
class UltrasoundPoseDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.img_dir = os.path.join(root_dir, "images")
        self.labels_df = pd.read_csv(os.path.join(root_dir, "labels.csv"))
        self.transform = transform
        
        # é¢„è®¡ç®—ä½ç½®ç»Ÿè®¡ä¿¡æ¯ (ç”¨äºå½’ä¸€åŒ–)
        # ä»…é’ˆå¯¹ä½ç½® (pos_x, pos_y, pos_z) è¿›è¡Œå½’ä¸€åŒ–ï¼Œå››å…ƒæ•°ä¸éœ€è¦
        pos_data = self.labels_df[['pos_x', 'pos_y', 'pos_z']].values
        self.pos_mean = torch.tensor(pos_data.mean(axis=0), dtype=torch.float32)
        self.pos_std = torch.tensor(pos_data.std(axis=0), dtype=torch.float32)
        
        print(f"ğŸ“Š æ•°æ®é›†ç»Ÿè®¡: Pos Mean={self.pos_mean.numpy()}, Std={self.pos_std.numpy()}")

    def __len__(self):
        return len(self.labels_df)

    def __getitem__(self, idx):
        # è¯»å–å›¾åƒ
        img_name = self.labels_df.iloc[idx]['filename']
        img_path = os.path.join(self.img_dir, img_name)
        
        # è¯»å–ç°åº¦å›¾
        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
        if image is None:
            raise FileNotFoundError(f"Image not found: {img_path}")
            
        # [1, H, W] å½’ä¸€åŒ–
        image = image.astype(np.float32) / 255.0
        image = torch.from_numpy(image).unsqueeze(0)

        if self.transform:
            image = self.transform(image)

        # è¯»å–æ ‡ç­¾
        row = self.labels_df.iloc[idx]
        pos = np.array([row['pos_x'], row['pos_y'], row['pos_z']], dtype=np.float32)
        quat = np.array([row['quat_x'], row['quat_y'], row['quat_z'], row['quat_w']], dtype=np.float32)
        
        # ä½ç½®å½’ä¸€åŒ– (Z-Score Normalization)
        # è¿™å¯¹äºå¹³è¡¡ Loss éå¸¸é‡è¦ï¼Œè®©ä½ç½®æ•°å€¼èŒƒå›´æ¥è¿‘ 0~1
        pos = (torch.from_numpy(pos) - self.pos_mean) / self.pos_std
        quat = torch.from_numpy(quat) # å››å…ƒæ•°æœ¬èº«èŒƒå›´å°±æ˜¯ -1~1ï¼Œæ— éœ€å½’ä¸€åŒ–
        
        # åˆå¹¶ä¸º 7D å‘é‡
        label = torch.cat([pos, quat])
        
        return image, label

# ================= 2. æ¨¡å‹å®šä¹‰ (æ–¹æ¡ˆ 3: å¼ºåˆ¶å½’ä¸€åŒ–) =================
class PoseResNet(nn.Module):
    def __init__(self, pretrained=True):
        super(PoseResNet, self).__init__()
        self.backbone = models.resnet18(weights=models.ResNet18_Weights.DEFAULT if pretrained else None)
        
        # ä¿®æ”¹ç¬¬ä¸€å±‚é€‚åº”å•é€šé“
        original_first_layer = self.backbone.conv1
        self.backbone.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)
        with torch.no_grad():
            self.backbone.conv1.weight.data = original_first_layer.weight.data.mean(dim=1, keepdim=True)

        # ä¿®æ”¹å…¨è¿æ¥å±‚è¾“å‡º 7 ç»´
        num_features = self.backbone.fc.in_features
        self.backbone.fc = nn.Linear(num_features, 7)

    def forward(self, x):
        x = self.backbone(x)
        
        # [æ–¹æ¡ˆ 3 æ ¸å¿ƒ]ï¼šç¡¬æ€§çº¦æŸ (Hard Constraint)
        # å°†è¾“å‡ºå‘é‡æ‹†åˆ†ä¸º ä½ç½®(3) å’Œ å§¿æ€(4)
        pos = x[:, :3]
        quat_raw = x[:, 3:]
        
        # å¼ºåˆ¶å››å…ƒæ•°å½’ä¸€åŒ–ï¼Œä½¿å…¶ä½äºå•ä½è¶…çƒé¢ä¸Š
        # è¿™æ ·ç½‘ç»œåªéœ€è¦å­¦ä¹ æ–¹å‘ï¼Œä¸éœ€è¦å­¦ä¹ æ¨¡é•¿ï¼Œæå¤§é™ä½å§¿æ€å›å½’éš¾åº¦
        quat_norm = torch.nn.functional.normalize(quat_raw, p=2, dim=1)
        
        return torch.cat([pos, quat_norm], dim=1)

# ================= 3. æŸå¤±å‡½æ•° (æ–¹æ¡ˆ 1: è‡ªåŠ¨åŠ æƒ) =================
class AutomaticWeightedLoss(nn.Module):
    """
    åŸºäºåŒæ–¹å·®ä¸ç¡®å®šæ€§ (Homoscedastic Uncertainty) çš„å¤šä»»åŠ¡ Loss
    Loss = (1/2Ïƒ1^2)*L1 + log(Ïƒ1) + (1/2Ïƒ2^2)*L2 + log(Ïƒ2)
    """
    def __init__(self, num_tasks=2):
        super(AutomaticWeightedLoss, self).__init__()
        # åˆå§‹åŒ–å¯å­¦ä¹ çš„å‚æ•° log_var (åˆå§‹åŒ–ä¸º 0)
        self.log_vars = nn.Parameter(torch.zeros(num_tasks))
        self.l1_loss = nn.L1Loss() # ä½ç½®ä½¿ç”¨ L1 Loss (å¯¹å¼‚å¸¸å€¼æ›´é²æ£’)

    def forward(self, pred, target):
        # æ‹†åˆ†
        pos_pred, quat_pred = pred[:, :3], pred[:, 3:]
        pos_target, quat_target = target[:, :3], target[:, 3:]
        
        # --- ä»»åŠ¡ 1: ä½ç½® Loss (åŸºäºå½’ä¸€åŒ–åçš„åæ ‡) ---
        loss_pos_raw = self.l1_loss(pos_pred, pos_target)
        
        # åŠ¨æ€åŠ æƒå…¬å¼
        # prec_pos = exp(-log_var) ç›¸å½“äº 1/Ïƒ^2
        precision_pos = torch.exp(-self.log_vars[0])
        weighted_loss_pos = 0.5 * precision_pos * loss_pos_raw + 0.5 * self.log_vars[0]
        
        # --- ä»»åŠ¡ 2: å§¿æ€ Loss (Geodesic Distance) ---
        # Loss = 1 - |<q1, q2>|
        # å³ä½¿æ¨¡å‹è¾“å‡ºäº†å½’ä¸€åŒ–å››å…ƒæ•°ï¼Œç‚¹ç§¯ä»å¯èƒ½ç•¥å¤§äº1æˆ–ç•¥å°äº-1 (æ•°å€¼è¯¯å·®)ï¼Œclampä¸€ä¸‹
        dot_product = torch.sum(quat_pred * quat_target, dim=1)
        loss_quat_raw = 1.0 - torch.mean(torch.abs(dot_product))
        
        precision_quat = torch.exp(-self.log_vars[1])
        weighted_loss_quat = 0.5 * precision_quat * loss_quat_raw + 0.5 * self.log_vars[1]
        
        # æ€» Loss
        total_loss = weighted_loss_pos + weighted_loss_quat
        
        return total_loss, loss_pos_raw, loss_quat_raw

# ================= 4. è®­ç»ƒä¸éªŒè¯æµç¨‹ =================
def train():
    print(f"ğŸš€ å¯åŠ¨è®­ç»ƒ (æ–¹æ¡ˆ3+æ–¹æ¡ˆ1)...")
    print(f"âš™ï¸  è®¾å¤‡: {DEVICE}")
    
    # 1. å‡†å¤‡æ•°æ®
    if not os.path.exists(os.path.join(DATASET_DIR, "labels.csv")):
        print("âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ•°æ®é›†ï¼Œè¯·å…ˆè¿è¡Œ generate_dataset.py")
        return

    full_dataset = UltrasoundPoseDataset(DATASET_DIR)
    
    # ä¿å­˜ç»Ÿè®¡æ•°æ®ç”¨äºåå½’ä¸€åŒ–éªŒè¯
    stats = {
        'mean': full_dataset.pos_mean.to(DEVICE),
        'std': full_dataset.pos_std.to(DEVICE)
    }
    
    test_size = int(len(full_dataset) * TEST_SPLIT)
    train_size = len(full_dataset) - test_size
    train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])
    
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)

    # 2. åˆå§‹åŒ–æ¨¡å‹ä¸Loss
    model = PoseResNet().to(DEVICE)
    criterion = AutomaticWeightedLoss().to(DEVICE)
    
    # [å…³é”®] å°† Loss çš„ log_vars ä¹ŸåŠ å…¥ä¼˜åŒ–å™¨
    # é€šå¸¸ç»™ log_vars ä¸€ä¸ªç¨å¤§çš„å­¦ä¹ ç‡æœ‰åŠ©äºå¿«é€Ÿæ‰¾åˆ°å¹³è¡¡ç‚¹
    optimizer = optim.Adam([
        {'params': model.parameters()},
        {'params': criterion.parameters(), 'lr': 1e-3} 
    ], lr=LEARNING_RATE)
    
    # 3. è®­ç»ƒå¾ªç¯
    history = {'train_loss': [], 'val_pos_err': [], 'val_quat_err': []}
    
    for epoch in range(NUM_EPOCHS):
        model.train()
        epoch_loss = 0.0
        
        # æ‰“å°å½“å‰çš„æƒé‡åˆ†é… (Debugç”¨)
        w_pos = torch.exp(-criterion.log_vars[0]).item()
        w_quat = torch.exp(-criterion.log_vars[1]).item()
        
        pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS} [W_pos:{w_pos:.2f}, W_quat:{w_quat:.2f}]")
        
        for imgs, labels in pbar:
            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)
            
            optimizer.zero_grad()
            outputs = model(imgs)
            
            loss, l_pos, l_quat = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            
            epoch_loss += loss.item()
            pbar.set_postfix({'Loss': f"{loss.item():.2f}", 'L_P': f"{l_pos.item():.3f}", 'L_Q': f"{l_quat.item():.3f}"})
            
        avg_epoch_loss = epoch_loss / len(train_loader)
        history['train_loss'].append(avg_epoch_loss)
        
        # éªŒè¯ (è®¡ç®—çœŸå®çš„ç‰©ç†è¯¯å·®)
        val_pos_mm, val_quat_dist = evaluate(model, test_loader, stats)
        history['val_pos_err'].append(val_pos_mm)
        history['val_quat_err'].append(val_quat_dist)
        
        print(f"   Done. Train Loss: {avg_epoch_loss:.4f}")
        print(f"   >> Val Error: Position = {val_pos_mm:.2f} mm | Rotation = {val_quat_dist:.4f} (Geodesic)")

    # 4. ä¿å­˜
    torch.save(model.state_dict(), "resnet18_auto_weighted.pth")
    print("âœ… æ¨¡å‹å·²ä¿å­˜è‡³ resnet18_auto_weighted.pth")
    
    # ç»˜å›¾
    plot_history(history)

def evaluate(model, loader, stats):
    model.eval()
    total_pos_error = 0.0
    total_quat_error = 0.0
    
    with torch.no_grad():
        for imgs, labels in loader:
            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)
            outputs = model(imgs)
            
            # åå½’ä¸€åŒ–ä½ç½®ï¼Œè®¡ç®—çœŸå®ç‰©ç†è¯¯å·® (mm)
            pos_pred_real = outputs[:, :3] * stats['std'] + stats['mean']
            pos_gt_real = labels[:, :3] * stats['std'] + stats['mean']
            
            # ä½ç½®è¯¯å·® (L2 Euclidean)
            batch_pos_err = torch.norm(pos_pred_real - pos_gt_real, dim=1).mean().item()
            total_pos_error += batch_pos_err
            
            # å§¿æ€è¯¯å·® (Geodesic distance: 1 - |q1.q2|)
            # outputs å·²ç»åœ¨ forward ä¸­å¼ºåˆ¶å½’ä¸€åŒ–äº†ï¼Œlabels ä¹Ÿæ˜¯å½’ä¸€åŒ–çš„
            dot = torch.sum(outputs[:, 3:] * labels[:, 3:], dim=1)
            batch_quat_err = (1.0 - torch.abs(dot)).mean().item()
            total_quat_error += batch_quat_err
            
    return total_pos_error / len(loader), total_quat_error / len(loader)

def plot_history(hist):
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
    
    ax1.plot(hist['val_pos_err'], 'b-')
    ax1.set_title("Position Error (mm)")
    ax1.set_xlabel("Epoch")
    ax1.grid(True)
    
    ax2.plot(hist['val_quat_err'], 'r-')
    ax2.set_title("Rotation Error (1 - |q.q|)")
    ax2.set_xlabel("Epoch")
    ax2.grid(True)
    
    plt.savefig("training_metrics.png")
    print("ğŸ“ˆ è¯„ä¼°æ›²çº¿å·²ä¿å­˜è‡³ training_metrics.png")

# ================= 5. æ¨ç†æ¼”ç¤º =================
def run_demo():
    print(f"\nğŸ”® æ¨ç†æ¼”ç¤º...")
    if not os.path.exists("resnet18_auto_weighted.pth"): return
    
    # éœ€è¦é‡æ–°åŠ è½½ Dataset è·å–ç»Ÿè®¡æ•°æ®ç”¨äºåå½’ä¸€åŒ–
    ds = UltrasoundPoseDataset(DATASET_DIR)
    mean, std = ds.pos_mean.to(DEVICE), ds.pos_std.to(DEVICE)
    
    model = PoseResNet().to(DEVICE)
    model.load_state_dict(torch.load("resnet18_auto_weighted.pth", map_location=DEVICE))
    model.eval()
    
    # è¯»å–ä¸€å¼ å›¾
    img_path = os.path.join(DATASET_DIR, "images", "000000.png")
    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
    img_t = torch.from_numpy(img.astype(np.float32)/255.0).unsqueeze(0).unsqueeze(0).to(DEVICE)
    
    with torch.no_grad():
        out = model(img_t)[0]
    
    # è§£æç»“æœ
    pos_norm = out[:3]
    quat = out[3:]
    
    # åå½’ä¸€åŒ–ä½ç½®
    pos_real = pos_norm * std + mean
    
    print(f"   åŸå§‹è¾“å‡º (Norm Pos): {pos_norm.cpu().numpy()}")
    print(f"   çœŸå®ä½ç½® (Real Pos): {pos_real.cpu().numpy()} mm")
    print(f"   é¢„æµ‹å§¿æ€ (Quat): {quat.cpu().numpy()} (æ¨¡é•¿: {torch.norm(quat).item():.4f})")

if __name__ == "__main__":
    train()
    run_demo()